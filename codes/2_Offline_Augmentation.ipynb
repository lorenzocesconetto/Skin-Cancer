{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2 - Offline Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "data_original_dir = 'data_original'\n",
    "data_processed_dir = 'data_processed'\n",
    "split_dirs = ['train', 'test']\n",
    "diagnostic_classes = ['nv', 'mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df']\n",
    "img_format = 'jpg'\n",
    "\n",
    "num_aug_images_wanted = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Imports and notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up multiple outputs for cells\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Printing with markdown\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default imports\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from send2trash import send2trash\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed_dir_path = os.path.join('..', data_processed_dir)\n",
    "data_original_dir_path = os.path.join('..', data_original_dir)\n",
    "train_path = os.path.join(data_processed_dir_path, split_dirs[0])\n",
    "test_path = os.path.join(data_processed_dir_path, split_dirs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data augmentation offline and save to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nv 4723\n",
      "mel 772\n",
      "bkl 767\n",
      "bcc 366\n",
      "akiec 229\n",
      "vasc 102\n",
      "df 85\n"
     ]
    }
   ],
   "source": [
    "# Check number of examples of each class in the train set\n",
    "for cls in diagnostic_classes:\n",
    "    print(cls, len(os.listdir(os.path.join(train_path, cls))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 772 images belonging to 1 classes.\n",
      "Found 767 images belonging to 1 classes.\n",
      "Found 366 images belonging to 1 classes.\n",
      "Found 229 images belonging to 1 classes.\n",
      "Found 102 images belonging to 1 classes.\n",
      "Found 85 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "set_random_seed(100)\n",
    "\n",
    "# Note that we are not augmenting class 'nv' which is the majority class\n",
    "aug_classes = [x for x in diagnostic_classes if x != 'nv']\n",
    "\n",
    "for cls in aug_classes:\n",
    "    aug_dir = 'aug_dir'\n",
    "    os.mkdir(aug_dir)\n",
    "    \n",
    "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "    os.mkdir(img_dir)\n",
    "\n",
    "    images = os.listdir(os.path.join(train_path, cls))\n",
    "\n",
    "    for img in images:\n",
    "            origin = os.path.join(train_path, cls, img)\n",
    "            destiny = os.path.join(img_dir, img)\n",
    "            _ = shutil.copyfile(origin, destiny)\n",
    "\n",
    "    save_path = os.path.join(train_path, cls)\n",
    "    \n",
    "    datagen = ImageDataGenerator(rotation_range=180,\n",
    "                                 width_shift_range=0.1,\n",
    "                                 height_shift_range=0.1,\n",
    "                                 zoom_range=0.1,\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True,\n",
    "                                 fill_mode='nearest',\n",
    "#                                brightness_range=(0.9, 1.1)\n",
    "                                )\n",
    "\n",
    "    batch_size = 50\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(aug_dir,\n",
    "                                              save_to_dir=save_path,\n",
    "                                              save_format=img_format,\n",
    "                                              target_size=(224, 224),\n",
    "                                              batch_size=batch_size)\n",
    "    \n",
    "    num_files = len(os.listdir(img_dir))\n",
    "    num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))\n",
    "\n",
    "    # run the generator and create about 6000 augmented images\n",
    "    for i in range(0, num_batches):\n",
    "        imgs, labels = next(aug_datagen)\n",
    "    \n",
    "    # delete temporary directory with the raw image files\n",
    "    send2trash(aug_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nv 4723\n",
      "mel 1022\n",
      "bkl 1017\n",
      "bcc 982\n",
      "akiec 966\n",
      "vasc 714\n",
      "df 900\n"
     ]
    }
   ],
   "source": [
    "# Check examples of each class\n",
    "for cls in diagnostic_classes:\n",
    "    print(cls, len(os.listdir(os.path.join(data_processed_dir_path, split_dirs[0], cls))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
