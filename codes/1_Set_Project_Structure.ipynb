{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1 - Set Project Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Imports and notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up multiple outputs for cells\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Printing with markdown\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default imports\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from send2trash import send2trash\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('../skin-cancer-mnist-ham10000'):\n",
    "    os.rename(src='../skin-cancer-mnist-ham10000', dst=DATA_ORIGINAL_DIR_PATH, src_dir_fd=None, dst_dir_fd=None)\n",
    "    print('Renamed directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Directories setup & train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Create directories from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building directory structure...\n",
      "Created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create directory structure\n",
    "if os.path.isdir(DATA_PROCESSED_DIR_PATH):\n",
    "    print('Reseting project directory structure...')\n",
    "    send2trash(DATA_PROCESSED_DIR_PATH)\n",
    "\n",
    "print('Building directory structure...')\n",
    "os.mkdir(DATA_PROCESSED_DIR_PATH)\n",
    "for split in SPLIT_DIRS:\n",
    "    os.mkdir(os.path.join(DATA_PROCESSED_DIR_PATH, split))\n",
    "    for cls in BINARY_CLASSES:\n",
    "        os.mkdir(os.path.join(DATA_PROCESSED_DIR_PATH, split, cls))\n",
    "print('Created successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Train, test, validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_ORIGINAL_DIR_PATH, 'HAM10000_metadata.csv'))\n",
    "df.set_index('image_id', inplace=True)\n",
    "df_all_except_mel = df[df['dx'] != 'mel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = pd.read_csv('../ISIC-2019/ISIC_2019_Training_Metadata.csv')\n",
    "df_2019_target = pd.read_csv('../ISIC-2019/ISIC_2019_Training_GroundTruth.csv', index_col='image')\n",
    "df_2019_target = df_2019_target.astype(int)\n",
    "df_2019_target_mel = df_2019_target[df_2019_target['MEL'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mel = pd.merge(left=df_2019_target_mel, right=df_2019[['image', 'lesion_id']], on='image', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4522"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows have ['lesion_id'] missing\n",
    "df_mel['lesion_id'].isna().sum()\n",
    "len(df_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter: 10,015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all images in the old ISIC are in the new one\n",
    "counter = 0\n",
    "for old_img in df.index.values:\n",
    "    if old_img in df_2019.image.values:\n",
    "        counter += 1\n",
    "print('counter:', '{:,}'.format(counter))\n",
    "counter == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there is any overlap\n",
    "df_mel['image'].isin(df_all_except_mel.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_on_column(df, column_to_split, test_rate=0.15, val_rate=0.15, random_seed=100):\n",
    "    # Setting random seed for the split\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    num_of_missing = df[column_to_split].isnull().sum()\n",
    "    fill_missing_values = ['missing_' + str(x) for x in range(num_of_missing)]\n",
    "    \n",
    "    null_indices = df[df[column_to_split].isna()].index\n",
    "    for i, fill_label in zip(null_indices, fill_missing_values):\n",
    "        df.loc[i, column_to_split] = fill_label\n",
    "    \n",
    "    values = df[column_to_split].unique().tolist()\n",
    "    \n",
    "    test_size = round(test_rate * len(values))\n",
    "    val_size = round(val_rate * len(values))\n",
    "\n",
    "    test_val_values = random.sample(population=values, k=test_size + val_size)\n",
    "    test_values = random.sample(population=test_val_values, k=test_size)\n",
    "    val_values = [x for x in test_val_values if x not in test_values]\n",
    "\n",
    "    df_train = df[~df[column_to_split].isin(test_val_values)]\n",
    "    df_test = df[df[column_to_split].isin(test_values)]\n",
    "    df_val = df[df[column_to_split].isin(val_values)]\n",
    "    \n",
    "    return df_train, df_test, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df_train, m_df_test, m_df_val = train_test_split_on_column(df_mel, 'lesion_id')\n",
    "nm_df_train, nm_df_test, nm_df_val = train_test_split_on_column(df_all_except_mel, 'lesion_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nm_df_train) + len(nm_df_test) + len(nm_df_val) == len(df_all_except_mel)\n",
    "len(m_df_train) + len(m_df_test) + len(m_df_val) == len(df_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nv      -1.843574\n",
       "bkl      0.600417\n",
       "bcc      0.475009\n",
       "akiec    0.804418\n",
       "vasc    -0.411110\n",
       "df       0.374840\n",
       "Name: dx, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nv       1.927868\n",
       "bkl     -1.057405\n",
       "bcc      0.090084\n",
       "akiec   -0.208834\n",
       "vasc    -0.838740\n",
       "df       0.087027\n",
       "Name: dx, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the split was stratified\n",
    "# % difference between train and test\n",
    "a = 100 * nm_df_train.dx.value_counts() / len(nm_df_train)\n",
    "b = 100 * nm_df_test.dx.value_counts() / len(nm_df_test)\n",
    "c = 100 * nm_df_val.dx.value_counts() / len(nm_df_val)\n",
    "\n",
    "a - b\n",
    "a - c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Copy images to appropriate directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_square(img, final_shape):\n",
    "    '''\n",
    "    Takes a PIL.JpegImagePlugin.JpegImageFile as input\n",
    "    '''\n",
    "    desired_size = max(img.size)\n",
    "    old_size = img.size\n",
    "    delta_w = desired_size - old_size[0]\n",
    "    delta_h = desired_size - old_size[1]\n",
    "    padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n",
    "    new_img = np.asarray(ImageOps.expand(img, padding))\n",
    "    return cv2.resize(new_img, final_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# TRANSFER IMAGES TO APROPIATE DIRECTORIES\n",
    "###########################################################\n",
    "\n",
    "# Data directories\n",
    "dir_part_1 = os.path.join(DATA_ORIGINAL_DIR_PATH, 'HAM10000_images_part_1')\n",
    "dir_part_2 = os.path.join(DATA_ORIGINAL_DIR_PATH, 'HAM10000_images_part_2')\n",
    "\n",
    "# List of images in each part\n",
    "images_part_1 = os.listdir(dir_part_1)\n",
    "images_part_2 = os.listdir(dir_part_2)\n",
    "\n",
    "# List in trainning and test data splits\n",
    "nm_train_images = nm_df_train.index.unique()\n",
    "nm_test_images = nm_df_test.index.unique()\n",
    "nm_val_images = nm_df_val.index.unique()\n",
    "\n",
    "for split, images in zip(SPLIT_DIRS, [nm_train_images, nm_test_images, nm_val_images]):\n",
    "    for img in images:\n",
    "        img_name = img + '.' + IMG_FORMAT\n",
    "        img_diagnosis = 'other'\n",
    "\n",
    "        origin = os.path.join(dir_part_1 if img_name in images_part_1 else dir_part_2, img_name)\n",
    "        destiny = os.path.join(DATA_PROCESSED_DIR_PATH, split, img_diagnosis, img_name)\n",
    "        \n",
    "        original_img = Image.open(origin)\n",
    "        processed_img = resize_to_square(original_img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        \n",
    "        plt.imsave(destiny, processed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "dir_part_3 = os.path.join(NEW_DATA_DIR_PATH, 'ISIC_2019_Training_Input')\n",
    "\n",
    "# List in trainning and test data splits\n",
    "m_train_images = m_df_train['image'].unique()\n",
    "m_test_images = m_df_test['image'].unique()\n",
    "m_val_images = m_df_val['image'].unique()\n",
    "\n",
    "for split, images in zip(SPLIT_DIRS, [m_train_images, m_test_images, m_val_images]):\n",
    "    for img in images:\n",
    "        img_name = img + '.' + IMG_FORMAT\n",
    "        img_diagnosis = 'mel'\n",
    "\n",
    "        origin = os.path.join(dir_part_3, img_name)\n",
    "        destiny = os.path.join(DATA_PROCESSED_DIR_PATH, split, img_diagnosis, img_name)\n",
    "        \n",
    "        original_img = Image.open(origin)\n",
    "        processed_img = resize_to_square(original_img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        \n",
    "        plt.imsave(destiny, processed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "other 70.18647494944956\n",
      "mel 69.04024767801857\n",
      "\n",
      "test\n",
      "other 14.816895079757359\n",
      "mel 16.143299425033174\n",
      "\n",
      "validation\n",
      "other 14.99662997079308\n",
      "mel 14.816452896948254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check proportion for each class\n",
    "for i in range(len(SPLIT_DIRS)):\n",
    "    print(SPLIT_DIRS[i])\n",
    "    \n",
    "    for cls in BINARY_CLASSES:\n",
    "        cls_sizes = [len(os.listdir(os.path.join(DATA_PROCESSED_DIR_PATH, split, cls))) \n",
    "                      for split in SPLIT_DIRS]\n",
    "        print(cls, cls_sizes[i] / sum(cls_sizes) * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3122"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "730"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m_df_train)\n",
    "len(m_df_test)\n",
    "len(m_df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6248"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1319"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1335"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nm_df_train)\n",
    "len(nm_df_test)\n",
    "len(nm_df_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel, 2019 update 1)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_2019u1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
