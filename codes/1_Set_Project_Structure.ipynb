{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1 - Set Project Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Imports and notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up multiple outputs for cells\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Printing with markdown\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default imports\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from send2trash import send2trash\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('../skin-cancer-mnist-ham10000'):\n",
    "    os.rename(src='../skin-cancer-mnist-ham10000', dst=DATA_ORIGINAL_DIR_PATH, src_dir_fd=None, dst_dir_fd=None)\n",
    "    print('Renamed directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Directories setup & train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Create directories from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting project directory structure...\n",
      "Building directory structure...\n",
      "Created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create directory structure\n",
    "if os.path.isdir(DATA_PROCESSED_DIR_PATH):\n",
    "    print('Reseting project directory structure...')\n",
    "    send2trash(DATA_PROCESSED_DIR_PATH)\n",
    "\n",
    "print('Building directory structure...')\n",
    "os.mkdir(DATA_PROCESSED_DIR_PATH)\n",
    "for split in SPLIT_DIRS:\n",
    "    os.mkdir(os.path.join(DATA_PROCESSED_DIR_PATH, split))\n",
    "    for cls in DIAGNOSTIC_CLASSES:\n",
    "        os.mkdir(os.path.join(DATA_PROCESSED_DIR_PATH, split, cls))\n",
    "print('Created successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Train, test, validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_ORIGINAL_DIR_PATH, 'HAM10000_metadata.csv'))\n",
    "df.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for the split\n",
    "random.seed(100)\n",
    "\n",
    "# We're splitting on lesion_id to avoid data leakage\n",
    "test_rate = 0.15\n",
    "val_rate = 0.15\n",
    "\n",
    "lesions = df.lesion_id.unique().tolist()\n",
    "test_size = round(test_rate * len(lesions))\n",
    "val_size = round(val_rate * len(lesions))\n",
    "\n",
    "test_val_lesions = random.sample(population=lesions, k=test_size + val_size)\n",
    "test_lesions = random.sample(population=test_val_lesions, k=test_size)\n",
    "val_lesions = [x for x in test_val_lesions if x not in test_lesions]\n",
    "\n",
    "df_train = df[~df.lesion_id.isin(test_val_lesions)] \n",
    "df_test = df[df.lesion_id.isin(test_lesions)]\n",
    "df_val = df[df.lesion_id.isin(val_lesions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "akiec   -0.946704\n",
       "bcc      0.524280\n",
       "bkl     -0.282594\n",
       "df       0.123424\n",
       "mel     -0.076202\n",
       "nv       0.496146\n",
       "vasc     0.161650\n",
       "Name: dx, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nv       0.182502\n",
       "mel     -0.954642\n",
       "bkl     -0.289346\n",
       "bcc     -0.091907\n",
       "akiec    0.841355\n",
       "vasc     0.042418\n",
       "df       0.269619\n",
       "Name: dx, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the split was stratified\n",
    "# % difference between train and test\n",
    "a = 100 * df_train.dx.value_counts() / len(df_train)\n",
    "b = 100 * df_test.dx.value_counts() / len(df_test)\n",
    "c = 100 * df_val.dx.value_counts() / len(df_val)\n",
    "\n",
    "a - b\n",
    "a - c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Copy images to appropriate directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_square(img):\n",
    "    '''\n",
    "    Takes a PIL.JpegImagePlugin.JpegImageFile as input\n",
    "    '''\n",
    "    desired_size = max(img.size)\n",
    "    old_size = img.size\n",
    "    delta_w = desired_size - old_size[0]\n",
    "    delta_h = desired_size - old_size[1]\n",
    "    padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n",
    "    return ImageOps.expand(img, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directories\n",
    "dir_part_1 = os.path.join(DATA_ORIGINAL_DIR_PATH, 'HAM10000_images_part_1')\n",
    "dir_part_2 = os.path.join(DATA_ORIGINAL_DIR_PATH, 'HAM10000_images_part_2')\n",
    "\n",
    "# List of images in each part\n",
    "images_part_1 = os.listdir(dir_part_1)\n",
    "images_part_2 = os.listdir(dir_part_2)\n",
    "\n",
    "# List in trainning and test data splits\n",
    "train_images = df_train.index.unique()\n",
    "test_images = df_test.index.unique()\n",
    "val_images = df_val.index.unique()\n",
    "\n",
    "for split, images in zip(SPLIT_DIRS, [train_images, test_images, val_images]):\n",
    "    for img in images:\n",
    "        img_name = img + '.' + IMG_FORMAT\n",
    "        img_diagnosis = df.loc[img, 'dx']\n",
    "\n",
    "        origin = os.path.join(dir_part_1 if img_name in images_part_1 else dir_part_2, img_name)\n",
    "        destiny = os.path.join(DATA_PROCESSED_DIR_PATH, split, img_diagnosis, img_name)\n",
    "        \n",
    "        original_img = Image.open(origin)\n",
    "        processed_img = resize_to_square(original_img)\n",
    "        \n",
    "        processed_img.save(destiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "akiec 70.03058103975535\n",
      "bcc 71.20622568093385\n",
      "bkl 69.79071883530482\n",
      "df 73.91304347826086\n",
      "nv 70.4399701715138\n",
      "vasc 71.83098591549296\n",
      "mel 69.36208445642407\n",
      "\n",
      "test\n",
      "akiec 18.960244648318042\n",
      "bcc 13.424124513618677\n",
      "bkl 15.013648771610555\n",
      "df 13.91304347826087\n",
      "nv 14.660700969425802\n",
      "vasc 13.380281690140844\n",
      "mel 14.645103324348607\n",
      "\n",
      "validation\n",
      "akiec 11.009174311926607\n",
      "bcc 15.369649805447471\n",
      "bkl 15.195632393084624\n",
      "df 12.173913043478262\n",
      "nv 14.899328859060404\n",
      "vasc 14.788732394366196\n",
      "mel 15.992812219227314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check proportion for each class\n",
    "for i in range(len(SPLIT_DIRS)):\n",
    "    print(SPLIT_DIRS[i])\n",
    "    \n",
    "    for cls in DIAGNOSTIC_CLASSES:\n",
    "        cls_sizes = [len(os.listdir(os.path.join(DATA_PROCESSED_DIR_PATH, split, cls))) \n",
    "                      for split in SPLIT_DIRS]\n",
    "        print(cls, cls_sizes[i] / sum(cls_sizes) * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7044"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1477"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1494"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)\n",
    "len(df_test)\n",
    "len(df_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
