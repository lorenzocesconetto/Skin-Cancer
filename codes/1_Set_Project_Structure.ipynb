{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1 - Set Project Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Imports and notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up multiple outputs for cells\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Printing with markdown\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default imports\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from send2trash import send2trash\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('../skin-cancer-mnist-ham10000'):\n",
    "    os.rename(src='../skin-cancer-mnist-ham10000', dst=DATA_ORIGINAL_DIR_PATH, src_dir_fd=None, dst_dir_fd=None)\n",
    "    print('Renamed directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Directories setup & train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Create directories from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting project directory structure...\n",
      "Building directory structure...\n",
      "Created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create directory structure\n",
    "if os.path.isdir(DATA_PROCESSED_DIR_PATH):\n",
    "    print('Reseting project directory structure...')\n",
    "    send2trash(DATA_PROCESSED_DIR_PATH)\n",
    "\n",
    "print('Building directory structure...')\n",
    "os.mkdir(DATA_PROCESSED_DIR_PATH)\n",
    "\n",
    "for i, split in enumerate(SPLIT_DIRS):\n",
    "    os.mkdir(os.path.join(DATA_PROCESSED_DIR_PATH, split))\n",
    "    \n",
    "    if i == 0:\n",
    "        for cls in CLASSES_2019:\n",
    "            os.mkdir(os.path.join(DATA_PROCESSED_DIR_PATH, split, cls))\n",
    "    else:\n",
    "        os.mkdir(os.path.join(DATA_PROCESSED_DIR_PATH, split, 'mel'))\n",
    "        os.mkdir(os.path.join(DATA_PROCESSED_DIR_PATH, split, 'other'))\n",
    "        \n",
    "print('Created successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Train, test, validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = pd.read_csv('../ISIC-2019/ISIC_2019_Training_Metadata.csv')\n",
    "df_2019_target = pd.read_csv('../ISIC-2019/ISIC_2019_Training_GroundTruth.csv', \n",
    "                             index_col='image').drop('UNK', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_target = df_2019_target.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=df_2019_target, right=df_2019[['image', 'lesion_id']], \n",
    "              on='image', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    ISIC_0000000ISIC_0000001ISIC_0000002ISIC_00000...\n",
       "MEL                                                   4522\n",
       "NV                                                   12875\n",
       "BCC                                                   3323\n",
       "AK                                                     867\n",
       "BKL                                                   2624\n",
       "DF                                                     239\n",
       "VASC                                                   253\n",
       "SCC                                                    628\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many images for each lesion\n",
    "df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_on_column(df, column_to_split, test_rate=0.15, val_rate=0.15, random_seed=40):\n",
    "    # Setting random seed for the split\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    num_of_missing = df[column_to_split].isnull().sum()\n",
    "    fill_missing_values = ['missing_' + str(x) for x in range(num_of_missing)]\n",
    "    \n",
    "    null_indices = df[df[column_to_split].isna()].index\n",
    "    for i, fill_label in zip(null_indices, fill_missing_values):\n",
    "        df.loc[i, column_to_split] = fill_label\n",
    "    \n",
    "    values = df[column_to_split].unique().tolist()\n",
    "    \n",
    "    test_size = round(test_rate * len(values))\n",
    "    val_size = round(val_rate * len(values))\n",
    "\n",
    "    test_val_values = random.sample(population=values, k=test_size + val_size)\n",
    "    test_values = random.sample(population=test_val_values, k=test_size)\n",
    "    val_values = [x for x in test_val_values if x not in test_values]\n",
    "\n",
    "    df_train = df[~df[column_to_split].isin(test_val_values)]\n",
    "    df_test = df[df[column_to_split].isin(test_values)]\n",
    "    df_val = df[df[column_to_split].isin(val_values)]\n",
    "    \n",
    "    return df_train, df_test, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, df_val = train_test_split_on_column(df, 'lesion_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MEL     70.919947\n",
       "NV      70.392233\n",
       "BCC     71.291002\n",
       "AK      71.049596\n",
       "BKL     68.750000\n",
       "DF      68.200837\n",
       "VASC    73.122530\n",
       "SCC     71.974522\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MEL     14.329943\n",
       "NV      14.485437\n",
       "BCC     13.391514\n",
       "AK      17.070358\n",
       "BKL     15.967988\n",
       "DF      18.410042\n",
       "VASC    10.276680\n",
       "SCC     15.127389\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MEL     14.750111\n",
       "NV      15.122330\n",
       "BCC     15.317484\n",
       "AK      11.880046\n",
       "BKL     15.282012\n",
       "DF      13.389121\n",
       "VASC    16.600791\n",
       "SCC     12.898089\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the split was stratified\n",
    "all_counts = df.drop(['image', 'lesion_id'], axis=1).sum(axis=0)\n",
    "train_counts = df_train.drop(['image', 'lesion_id'], axis=1).sum(axis=0)\n",
    "test_counts = df_test.drop(['image', 'lesion_id'], axis=1).sum(axis=0)\n",
    "val_counts = df_val.drop(['image', 'lesion_id'], axis=1).sum(axis=0)\n",
    "\n",
    "100 * train_counts.divide(all_counts)\n",
    "100 * test_counts.divide(all_counts)\n",
    "100 * val_counts.divide(all_counts)\n",
    "\n",
    "# (train_counts + test_counts + val_counts).divide(all_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Copy and pre-process images to appropriate directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzocesconetto/Desktop/ITAU-ANALYTICS/Skin-Cancer/skin_env/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for data_frame in [df, df_train, df_test, df_val]:\n",
    "    # Set index\n",
    "    data_frame.set_index('image', inplace=True)\n",
    "\n",
    "    # Setup diagnostic column\n",
    "    data_frame['dx'] = data_frame.drop('lesion_id', axis=1).idxmax(axis=1).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_square(img, final_shape):\n",
    "    '''\n",
    "    Takes a PIL.JpegImagePlugin.JpegImageFile as input\n",
    "    '''\n",
    "    desired_size = max(img.size)\n",
    "    old_size = img.size\n",
    "    delta_w = desired_size - old_size[0]\n",
    "    delta_h = desired_size - old_size[1]\n",
    "    padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n",
    "    new_img = np.asarray(ImageOps.expand(img, padding))\n",
    "    return cv2.resize(new_img, final_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train\n",
      "ak [516, 100]\n",
      "bcc [1000, 383]\n",
      "bkl [783, 749]\n",
      "df [75, 88]\n",
      "nv [1000, 1000]\n",
      "vasc [82, 103]\n",
      "mel [1000, 761]\n",
      "scc [319, 133]\n",
      "\n",
      "test\n",
      "ak [131, 17]\n",
      "bcc [382, 63]\n",
      "bkl [200, 168, 30, 6, 12, 1, 1, 1]\n",
      "df [27, 17]\n",
      "nv [567, 1000, 2, 86, 1, 1, 1, 1, 2, 11, 1, 1, 8, 19, 2, 94, 19, 2, 5, 5, 2, 2, 3, 6, 4]\n",
      "vasc [11, 15]\n",
      "mel [389, 168, 1, 20, 1, 1, 1, 1, 4, 3, 1, 1, 1, 1, 4, 39, 4, 1, 2, 1, 2, 1, 1]\n",
      "scc [54, 41]\n",
      "\n",
      "validation\n",
      "ak [90, 13]\n",
      "bcc [441, 68]\n",
      "bkl [155, 182, 1, 41, 10, 10, 2]\n",
      "df [22, 10]\n",
      "nv [612, 1000, 1, 92, 1, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 10, 1, 3, 2, 3, 91, 25, 14, 8, 10, 7, 6, 3, 1, 2, 1, 1, 1, 1]\n",
      "vasc [18, 24]\n",
      "mel [402, 184, 1, 22, 1, 1, 1, 1, 1, 1, 1, 36, 2, 1, 4, 1, 3, 3, 1]\n",
      "scc [58, 23]\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "# TRANSFER IMAGES TO APROPIATE DIRECTORIES\n",
    "###########################################################\n",
    "\n",
    "# Data directory\n",
    "dir_path = os.path.join(NEW_DATA_DIR_PATH, 'ISIC_2019_Training_Input')\n",
    "\n",
    "for i, (split, data_frame_split, rate) in enumerate(zip(SPLIT_DIRS, [df_train, df_test, df_val], [.7, .15, .15])):\n",
    "    print()\n",
    "    print(split)\n",
    "    for disease in CLASSES_2019:\n",
    "        images = data_frame_split[data_frame_split['dx'] == disease].index.unique()\n",
    "\n",
    "        if i != 0 and disease != 'mel':\n",
    "            diag = 'other'\n",
    "        else:\n",
    "            diag = disease\n",
    "        \n",
    "#         allowed_shapes = [(1024, 1024, 3), (450, 600, 3), (680, 1024, 3)]\n",
    "        allowed_shapes = [(1024, 1024, 3), (450, 600, 3)]\n",
    "        counter = [0] * len(allowed_shapes)\n",
    "        \n",
    "        for img in images:\n",
    "            img_name = img + '.' + IMG_FORMAT\n",
    "            origin = os.path.join(dir_path, img_name)\n",
    "            original_img = Image.open(origin)\n",
    "            img_shape = np.asarray(original_img).shape\n",
    "            \n",
    "            if split != 'train' or img_shape in allowed_shapes:\n",
    "                if img_shape not in allowed_shapes:\n",
    "                    allowed_shapes.append(img_shape)\n",
    "                    counter.append(0)\n",
    "                    \n",
    "                index = allowed_shapes.index(img_shape)\n",
    "                \n",
    "                # Limit number of images of each shape\n",
    "                # limit = 2000 if disease == 'mel' else 1000\n",
    "                limit = 1000\n",
    "                if counter[index] >= limit:\n",
    "                    continue\n",
    "                \n",
    "                counter[index] += 1\n",
    "                \n",
    "                destiny = os.path.join(DATA_PROCESSED_DIR_PATH, split, diag, img_name)\n",
    "\n",
    "                original_img = Image.open(origin)\n",
    "                processed_img = resize_to_square(original_img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "                plt.imsave(destiny, processed_img)\n",
    "        print(disease, counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "df 163\n",
      "ak 616\n",
      "bkl 1532\n",
      "vasc 185\n",
      "nv 2000\n",
      "bcc 1383\n",
      "scc 452\n",
      "mel 1761\n",
      "\n",
      "test\n",
      "other 3022\n",
      "mel 648\n",
      "\n",
      "validation\n",
      "other 3080\n",
      "mel 667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check proportion for each class\n",
    "for i in range(len(SPLIT_DIRS)):\n",
    "    print(SPLIT_DIRS[i])\n",
    "    dirs = [x for x in os.listdir(os.path.join(DATA_PROCESSED_DIR_PATH, SPLIT_DIRS[i])) if x[0] != '.']\n",
    "    for cls in dirs:\n",
    "        print(cls, len([x for x in os.listdir(os.path.join(DATA_PROCESSED_DIR_PATH, SPLIT_DIRS[i], cls)) if x[0] != '.']))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
