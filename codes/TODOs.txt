TODO


AGORA:
    - Equilibrar imagens de cada shape do melanoma (e das demais também(?)) pelo augmentation.
    - Refazer VGG_v7 aumentando o augmentation para: 2.000, 800, 1.200, 1.400, 1.600
    - VGG_v7: Verificar doenças que se confundem com melanoma
    
    - Write article
        - OK: Modelos Baseline
        - Motivação do trabalho na introdução (Necessidade)
        - Explicar quais equipamentos geraram as imagens
        - Explicar que tipo de augmentation foi utilizado (translação, rotação), número de camadas descongeladas, batch size, número de épocas...
        - História até chegar onde cheguei (os leaks)
        - Explorar curva ROC AUC
        - Identificar interpretabildiade com casos que acerta, erra, fica na dúvida
        - Comparar Lime e LRP
        - Sem Augmentation vs com Augmentation: Bump de AUC e qualidade interpretabilidade
        - Efeito de mais Augmentation


DONE:
    - OK: Testar com (450, 600, 3), (1024, 1024, 3), (680, 1024, 3), (768, 1024, 3)
    - OK: Verificar o que o history = model.fit() está me retornando
    - OK: Testar deformando imagem com resize + Verificar se erra um shape específico.
    - OK: MELHOR, MENOR LEAK NO SHAPE: VGG_v7: (450, 600, 3), (1024, 1024, 3), (680, 1024, 3)
    - OK: DA LEAK NO SHAPE se usar somente: (450, 600, 3), (1024, 1024, 3)
    - OK: Fazer filtro para deixar pixels mais importantes que somam 90% do total
    
    
MAYBE:
    - Tentar Cyclical Learning rate.
    - SpRaY
    - + 90% AUC (cyclical learning rate)
    - Rerodar modelos garantindo mesma metodologia
    - Fazer a minha rede na mão (keras sequence)
    - Testar pré-processamento de deixar somente a pinta (zerar todos os demais pixels)
    - Testar pré-processamento para bordas
    - Slider para o threshold fazendo uma linha vertical e uma horizontal p/ ver TPR e FPR


FUTURE:
    - Try to improve using VGG19


FELIPE LODUR
    - 2 ou 3 densas
    - Learning curve: Variando um parâmetro
    - VGG, Inception, ResNet
    - Separar 3 imagens de cada classe p/ o Lime (acerta c/ certeza, + ou -, erra muito)
    - Estudar mais sobre interpretabilidade, outros pacotes, outras formas
    - Formatos de imagens RGB, HSV, HSL, CIELAB -> Qual a melhor representação para imagens?
    - 1) Modelo / 2) Interpretabilidade / 3) fomato imagem / 4) Imagens críticas: Interpretabilidade, semelhança a priori (pode ser distancia cosseno do embedding), probabilidade a posteriori (grau de certeza).
    - Embedding imagem (Pode usar os pesos do bottle neck do Auto encoder). Reconstruir a imagem sozinha ou com idade, etc.
    - Cluster de interpretacoes.


- VERRI
    - Entender Lime no detalhe.
    - Lime com múltiplas imagens (como interpretar).
    - Link com trabalho anterior.
    - Passar uma função.
    - Fazer uma funcao que pre-processa e faz o predict e passar essa para o Lime.


felipe@lodur.com.br
(31) 99290-8194

